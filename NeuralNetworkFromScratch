"```python
import numpy as np

class NeuralNetwork:
    def __init__(self, layers):
        self.layers = layers
        self.weights = []
        self.biases = []

        for i in range(len(layers) - 1):
            self.weights.append(np.random.randn(layers[i], layers[i+1]))
            self.biases.append(np.random.randn(layers[i+1]))

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def _sigmoid_derivative(self, x):
        return self._sigmoid(x) * (1 - self._sigmoid(x))

    def _feedforward(self, X):
        self.a = [X]
        self.z = []

        for i in range(len(self.layers) - 1):
            self.z.append(np.dot(self.a[-1], self.weights[i]) + self.biases[i])
            self.a.append(self._sigmoid(self.z[-1]))

        return self.a[-1]

    def _backpropagation(self, X, y, learning_rate):
        m = X.shape[0]
        dw = [np.zeros(w.shape) for w in self.weights]
        db = [np.zeros(b.shape) for b in self.biases]
        delta = [(self.a[-1] - y) * self._sigmoid_derivative(self.z[-1])]

        for l in range(len(self.layers) - 3, -1, -1):
            delta.append(np.dot(delta[-1], self.weights[l+1].T) * self._sigmoid_derivative(self.z[l]))
            dw[l] = np.dot(self.a[l].T, delta[-1]) / m
            db[l] = np.sum(delta[-1], axis=0, keepdims=True) / m

        for l in range(len(self.layers) - 2, -1, -1):
            self.weights[l] -= learning_rate * dw[l]
            self.biases[l] -= learning_rate * db[l]

    def train(self, X, y, epochs, learning_rate):
        for i in range(epochs):
            self._feedforward(X)
            self._backpropagation(X, y, learning_rate)

    def predict(self, X):
        return self._feedforward(X)

if __name__ == ""__main__"":
    X = np.array([[0,0], [0,1], [1,0], [1,1]])
    y = np.array([[0], [1], [1], [0]])

    nn = NeuralNetwork([2, 5, 1])

    nn.train(X, y, epochs=2000, learning_rate=1)

    print(""Predictions:\n"", nn.predict(X))
```
```"
